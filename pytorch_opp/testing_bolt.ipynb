{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "9\n",
      "is gpu?: False 0\n"
     ]
    }
   ],
   "source": [
    "# check conda connected\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "print(np.apply_along_axis(lambda row: sum(row)**2, 0, np.arange(9,9,9)))\n",
    "\n",
    "print(9)\n",
    "\n",
    "\n",
    "#Check torch install and running cudas\n",
    "#!pip3 install torch\n",
    "import torch\n",
    "\n",
    "print(\"is gpu?:\",\n",
    "torch.cuda.is_available(),\n",
    "torch.cuda.device_count())\n",
    "\n",
    "#WARN: Can't ssh into google colab. Going to have to do locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "/home/cbenham/bolt/pytorch_opp/warp_perspective/build/libwarp_perspective.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_28834/1589957839.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_GLIBCXX_USE_CXX11_ABI\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_library\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"warp_perspective/build/libwarp_perspective.so\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmy_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarp_perspective\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmy_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarp_perspective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local/miniconda/lib/python3.7/site-packages/torch/_ops.py\u001b[0m in \u001b[0;36mload_library\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0;31m# static (global) initialization code in order to register custom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0;31m# operators with the JIT.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m             \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloaded_libraries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local/miniconda/lib/python3.7/ctypes/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: /home/cbenham/bolt/pytorch_opp/warp_perspective/build/libwarp_perspective.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch._C._GLIBCXX_USE_CXX11_ABI)\n",
    "torch.ops.load_library(\"warp_perspective/build/libwarp_perspective.so\")\n",
    "print(torch.ops.my_ops.warp_perspective)\n",
    "print(torch.ops.my_ops.warp_perspective(torch.randn(32, 32), torch.rand(3, 3)))\n",
    "\n",
    "def compute(x, y, z):\n",
    "    return x.matmul(y) + torch.relu(z)\n",
    "  \n",
    "inputs = [torch.randn(4, 8), torch.randn(8, 5), torch.randn(4, 5)]\n",
    "trace = torch.jit.trace(compute, inputs)\n",
    "print(trace.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%x.1 : Float(4, 8, strides=[8, 1], requires_grad=0, device=cpu),\n",
      "      %y : Float(8, 5, strides=[5, 1], requires_grad=0, device=cpu),\n",
      "      %z : Float(8, 5, strides=[5, 1], requires_grad=0, device=cpu)):\n",
      "  %3 : int = prim::Constant[value=3]() # /tmp/ipykernel_7860/2329074975.py:2:0\n",
      "  %4 : int = prim::Constant[value=6]() # /tmp/ipykernel_7860/2329074975.py:2:0\n",
      "  %5 : NoneType = prim::Constant()\n",
      "  %6 : Device = prim::Constant[value=\"cpu\"]() # /tmp/ipykernel_7860/2329074975.py:2:0\n",
      "  %7 : bool = prim::Constant[value=0]() # /tmp/ipykernel_7860/2329074975.py:2:0\n",
      "  %8 : Float(3, 3, strides=[3, 1], requires_grad=0, device=cpu) = aten::eye(%3, %4, %5, %6, %7) # /tmp/ipykernel_7860/2329074975.py:2:0\n",
      "  %x : Float(8, 8, strides=[8, 1], requires_grad=0, device=cpu) = my_ops::warp_perspective(%x.1, %8) # /root/local/miniconda/lib/python3.7/site-packages/torch/_ops.py:143:0\n",
      "  %10 : Float(8, 5, strides=[5, 1], requires_grad=0, device=cpu) = aten::matmul(%x, %y) # /tmp/ipykernel_7860/2329074975.py:3:0\n",
      "  %11 : Float(8, 5, strides=[5, 1], requires_grad=0, device=cpu) = aten::relu(%z) # /tmp/ipykernel_7860/2329074975.py:3:0\n",
      "  %12 : int = prim::Constant[value=1]() # /tmp/ipykernel_7860/2329074975.py:3:0\n",
      "  %13 : Float(8, 5, strides=[5, 1], requires_grad=0, device=cpu) = aten::add(%10, %11, %12) # /tmp/ipykernel_7860/2329074975.py:3:0\n",
      "  return (%13)\n",
      "\n",
      "graph(%x.1 : Tensor,\n",
      "      %y.1 : Tensor):\n",
      "  %23 : int = prim::Constant[value=1]()\n",
      "  %3 : int = prim::Constant[value=0]() # /tmp/ipykernel_7860/2329074975.py:11:12\n",
      "  %8 : int = prim::Constant[value=42]() # /tmp/ipykernel_7860/2329074975.py:11:21\n",
      "  %13 : int = prim::Constant[value=5]() # /tmp/ipykernel_7860/2329074975.py:12:10\n",
      "  %14 : int = prim::Constant[value=10]() # /tmp/ipykernel_7860/2329074975.py:14:10\n",
      "  %5 : Tensor = aten::select(%x.1, %3, %3) # /tmp/ipykernel_7860/2329074975.py:11:10\n",
      "  %7 : Tensor = aten::select(%5, %3, %3) # /tmp/ipykernel_7860/2329074975.py:11:10\n",
      "  %9 : Tensor = aten::eq(%7, %8) # /tmp/ipykernel_7860/2329074975.py:11:10\n",
      "  %11 : bool = aten::Bool(%9) # /tmp/ipykernel_7860/2329074975.py:11:5\n",
      "  %z : int = prim::If(%11) # /tmp/ipykernel_7860/2329074975.py:11:2\n",
      "    block0():\n",
      "      -> (%13)\n",
      "    block1():\n",
      "      -> (%14)\n",
      "  %21 : Tensor = aten::matmul(%x.1, %y.1) # /tmp/ipykernel_7860/2329074975.py:15:9\n",
      "  %24 : Tensor = aten::add(%21, %z, %23) # /tmp/ipykernel_7860/2329074975.py:15:9\n",
      "  return (%24)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def compute(x, y, z):\n",
    "    x = torch.ops.my_ops.warp_perspective(x, torch.eye(3))\n",
    "    return x.matmul(y) + torch.relu(z)\n",
    "  \n",
    "inputs = [torch.randn(4, 8), torch.randn(8, 5), torch.randn(8, 5)]\n",
    "trace = torch.jit.trace(compute, inputs)\n",
    "print(trace.graph)\n",
    "\n",
    "@torch.jit.script\n",
    "def compute(x, y):\n",
    "  if bool(x[0][0] == 42):\n",
    "      z = 5\n",
    "  else:\n",
    "      z = 10\n",
    "  return x.matmul(y) + z\n",
    "print(compute.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%x.1 : Tensor,\n",
      "      %y.1 : Tensor):\n",
      "  %29 : int = prim::Constant[value=1]()\n",
      "  %19 : NoneType = prim::Constant()\n",
      "  %3 : int = prim::Constant[value=0]() # /tmp/ipykernel_7860/1391356468.py:3:12\n",
      "  %6 : int = prim::Constant[value=42]() # /tmp/ipykernel_7860/1391356468.py:3:18\n",
      "  %11 : int = prim::Constant[value=5]() # /tmp/ipykernel_7860/1391356468.py:4:10\n",
      "  %12 : int = prim::Constant[value=10]() # /tmp/ipykernel_7860/1391356468.py:6:10\n",
      "  %18 : int = prim::Constant[value=3]() # /tmp/ipykernel_7860/1391356468.py:7:53\n",
      "  %5 : Tensor = aten::select(%x.1, %3, %3) # /tmp/ipykernel_7860/1391356468.py:3:10\n",
      "  %7 : Tensor = aten::eq(%5, %6) # /tmp/ipykernel_7860/1391356468.py:3:10\n",
      "  %9 : bool = aten::Bool(%7) # /tmp/ipykernel_7860/1391356468.py:3:5\n",
      "  %z : int = prim::If(%9) # /tmp/ipykernel_7860/1391356468.py:3:2\n",
      "    block0():\n",
      "      -> (%11)\n",
      "    block1():\n",
      "      -> (%12)\n",
      "  %23 : Tensor = aten::eye(%18, %19, %19, %19, %19) # /tmp/ipykernel_7860/1391356468.py:7:43\n",
      "  %x.7 : Tensor = my_ops::warp_perspective(%x.1, %23) # /tmp/ipykernel_7860/1391356468.py:7:6\n",
      "  %27 : Tensor = aten::matmul(%x.7, %y.1) # /tmp/ipykernel_7860/1391356468.py:8:9\n",
      "  %30 : Tensor = aten::add(%27, %z, %29) # /tmp/ipykernel_7860/1391356468.py:8:9\n",
      "  return (%30)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@torch.jit.script\n",
    "def compute(x, y):\n",
    "  if bool(x[0] == 42):\n",
    "      z = 5\n",
    "  else:\n",
    "      z = 10\n",
    "  x = torch.ops.my_ops.warp_perspective(x, torch.eye(3))\n",
    "  return x.matmul(y) + z\n",
    "\n",
    "print(compute.graph)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "8a6b5a67c5d774b05f6659b16625b575f0390caee0a071a25b205e3940b26b24"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
