{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "9\n",
      "is gpu?: False 0\n"
     ]
    }
   ],
   "source": [
    "# check conda connected\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "print(np.apply_along_axis(lambda row: sum(row)**2, 0, np.arange(9,9,9)))\n",
    "\n",
    "print(9)\n",
    "\n",
    "\n",
    "#Check torch install and running cudas\n",
    "#!pip3 install torch\n",
    "import torch\n",
    "\n",
    "print(\"is gpu?:\",\n",
    "torch.cuda.is_available(),\n",
    "torch.cuda.device_count())\n",
    "\n",
    "#WARN: Can't ssh into google colab. Going to have to do locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "my_ops.warp_perspective\n",
      "tensor([[-0.2018, -0.0656, -0.1311, -0.1475, -0.1475, -0.1475, -0.1475, -0.1475],\n",
      "        [-0.2243, -0.0690, -0.1242, -0.1397, -0.1397, -0.1397, -0.1397, -0.1397],\n",
      "        [-0.2381, -0.0845, -0.1320, -0.1397, -0.1397, -0.1397, -0.1397, -0.1397],\n",
      "        [-0.2372, -0.0828, -0.1242, -0.1320, -0.1397, -0.1397, -0.1397, -0.1397],\n",
      "        [-0.2502, -0.0854, -0.1242, -0.1320, -0.1320, -0.1397, -0.1397, -0.1397],\n",
      "        [-0.2084, -0.0863, -0.1294, -0.1466, -0.1466, -0.1466, -0.1553, -0.1553],\n",
      "        [-0.1281, -0.0854, -0.1294, -0.1380, -0.1466, -0.1466, -0.1466, -0.1553],\n",
      "        [-0.0298, -0.0828, -0.1208, -0.1380, -0.1466, -0.1466, -0.1466, -0.1466]])\n",
      "graph(%x : Float(4, 8, strides=[8, 1], requires_grad=0, device=cpu),\n",
      "      %y : Float(8, 5, strides=[5, 1], requires_grad=0, device=cpu),\n",
      "      %z : Float(4, 5, strides=[5, 1], requires_grad=0, device=cpu)):\n",
      "  %3 : Float(4, 5, strides=[5, 1], requires_grad=0, device=cpu) = aten::matmul(%x, %y) # /tmp/ipykernel_26022/1589957839.py:8:0\n",
      "  %4 : Float(4, 5, strides=[5, 1], requires_grad=0, device=cpu) = aten::relu(%z) # /tmp/ipykernel_26022/1589957839.py:8:0\n",
      "  %5 : int = prim::Constant[value=1]() # /tmp/ipykernel_26022/1589957839.py:8:0\n",
      "  %6 : Float(4, 5, strides=[5, 1], requires_grad=0, device=cpu) = aten::add(%3, %4, %5) # /tmp/ipykernel_26022/1589957839.py:8:0\n",
      "  return (%6)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch._C._GLIBCXX_USE_CXX11_ABI)\n",
    "torch.ops.load_library(\"warp_perspective/build/libwarp_perspective.so\")\n",
    "print(torch.ops.my_ops.warp_perspective)\n",
    "print(torch.ops.my_ops.warp_perspective(torch.randn(32, 32), torch.rand(3, 3)))\n",
    "\n",
    "def compute(x, y, z):\n",
    "    return x.matmul(y) + torch.relu(z)\n",
    "  \n",
    "inputs = [torch.randn(4, 8), torch.randn(8, 5), torch.randn(4, 5)]\n",
    "trace = torch.jit.trace(compute, inputs)\n",
    "print(trace.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%x.1 : Float(4, 8, strides=[8, 1], requires_grad=0, device=cpu),\n",
      "      %y : Float(8, 5, strides=[5, 1], requires_grad=0, device=cpu),\n",
      "      %z : Float(8, 5, strides=[5, 1], requires_grad=0, device=cpu)):\n",
      "  %3 : int = prim::Constant[value=3]() # /tmp/ipykernel_26022/2329074975.py:2:0\n",
      "  %4 : NoneType = prim::Constant()\n",
      "  %5 : NoneType = prim::Constant()\n",
      "  %6 : Device = prim::Constant[value=\"cpu\"]() # /tmp/ipykernel_26022/2329074975.py:2:0\n",
      "  %7 : bool = prim::Constant[value=0]() # /tmp/ipykernel_26022/2329074975.py:2:0\n",
      "  %8 : Float(3, 3, strides=[3, 1], requires_grad=0, device=cpu) = aten::eye(%3, %4, %5, %6, %7) # /tmp/ipykernel_26022/2329074975.py:2:0\n",
      "  %x : Float(8, 8, strides=[8, 1], requires_grad=0, device=cpu) = my_ops::warp_perspective(%x.1, %8) # /root/local/miniconda/lib/python3.8/site-packages/torch/_ops.py:661:0\n",
      "  %10 : Float(8, 5, strides=[5, 1], requires_grad=0, device=cpu) = aten::matmul(%x, %y) # /tmp/ipykernel_26022/2329074975.py:3:0\n",
      "  %11 : Float(8, 5, strides=[5, 1], requires_grad=0, device=cpu) = aten::relu(%z) # /tmp/ipykernel_26022/2329074975.py:3:0\n",
      "  %12 : int = prim::Constant[value=1]() # /tmp/ipykernel_26022/2329074975.py:3:0\n",
      "  %13 : Float(8, 5, strides=[5, 1], requires_grad=0, device=cpu) = aten::add(%10, %11, %12) # /tmp/ipykernel_26022/2329074975.py:3:0\n",
      "  return (%13)\n",
      "\n",
      "graph(%x.1 : Tensor,\n",
      "      %y.1 : Tensor):\n",
      "  %23 : int = prim::Constant[value=1]()\n",
      "  %3 : int = prim::Constant[value=0]() # /tmp/ipykernel_26022/2329074975.py:11:12\n",
      "  %8 : int = prim::Constant[value=42]() # /tmp/ipykernel_26022/2329074975.py:11:21\n",
      "  %13 : int = prim::Constant[value=5]() # /tmp/ipykernel_26022/2329074975.py:12:10\n",
      "  %14 : int = prim::Constant[value=10]() # /tmp/ipykernel_26022/2329074975.py:14:10\n",
      "  %5 : Tensor = aten::select(%x.1, %3, %3) # /tmp/ipykernel_26022/2329074975.py:11:10\n",
      "  %7 : Tensor = aten::select(%5, %3, %3) # /tmp/ipykernel_26022/2329074975.py:11:10\n",
      "  %9 : Tensor = aten::eq(%7, %8) # /tmp/ipykernel_26022/2329074975.py:11:10\n",
      "  %11 : bool = aten::Bool(%9) # /tmp/ipykernel_26022/2329074975.py:11:5\n",
      "  %z : int = prim::If(%11) # /tmp/ipykernel_26022/2329074975.py:11:2\n",
      "    block0():\n",
      "      -> (%13)\n",
      "    block1():\n",
      "      -> (%14)\n",
      "  %21 : Tensor = aten::matmul(%x.1, %y.1) # /tmp/ipykernel_26022/2329074975.py:15:9\n",
      "  %24 : Tensor = aten::add(%21, %z, %23) # /tmp/ipykernel_26022/2329074975.py:15:9\n",
      "  return (%24)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def compute(x, y, z):\n",
    "    x = torch.ops.my_ops.warp_perspective(x, torch.eye(3))\n",
    "    return x.matmul(y) + torch.relu(z)\n",
    "  \n",
    "inputs = [torch.randn(4, 8), torch.randn(8, 5), torch.randn(8, 5)]\n",
    "trace = torch.jit.trace(compute, inputs)\n",
    "print(trace.graph)\n",
    "\n",
    "@torch.jit.script\n",
    "def compute(x, y):\n",
    "  if bool(x[0][0] == 42):\n",
    "      z = 5\n",
    "  else:\n",
    "      z = 10\n",
    "  return x.matmul(y) + z\n",
    "print(compute.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%x.1 : Tensor,\n",
      "      %y.1 : Tensor):\n",
      "  %29 : int = prim::Constant[value=1]()\n",
      "  %19 : NoneType = prim::Constant()\n",
      "  %3 : int = prim::Constant[value=0]() # /tmp/ipykernel_26022/1391356468.py:3:12\n",
      "  %6 : int = prim::Constant[value=42]() # /tmp/ipykernel_26022/1391356468.py:3:18\n",
      "  %11 : int = prim::Constant[value=5]() # /tmp/ipykernel_26022/1391356468.py:4:10\n",
      "  %12 : int = prim::Constant[value=10]() # /tmp/ipykernel_26022/1391356468.py:6:10\n",
      "  %18 : int = prim::Constant[value=3]() # /tmp/ipykernel_26022/1391356468.py:7:53\n",
      "  %5 : Tensor = aten::select(%x.1, %3, %3) # /tmp/ipykernel_26022/1391356468.py:3:10\n",
      "  %7 : Tensor = aten::eq(%5, %6) # /tmp/ipykernel_26022/1391356468.py:3:10\n",
      "  %9 : bool = aten::Bool(%7) # /tmp/ipykernel_26022/1391356468.py:3:5\n",
      "  %z : int = prim::If(%9) # /tmp/ipykernel_26022/1391356468.py:3:2\n",
      "    block0():\n",
      "      -> (%11)\n",
      "    block1():\n",
      "      -> (%12)\n",
      "  %23 : Tensor = aten::eye(%18, %19, %19, %19, %19) # /tmp/ipykernel_26022/1391356468.py:7:43\n",
      "  %x.7 : Tensor = my_ops::warp_perspective(%x.1, %23) # /tmp/ipykernel_26022/1391356468.py:7:6\n",
      "  %27 : Tensor = aten::matmul(%x.7, %y.1) # /tmp/ipykernel_26022/1391356468.py:8:9\n",
      "  %30 : Tensor = aten::add(%27, %z, %29) # /tmp/ipykernel_26022/1391356468.py:8:9\n",
      "  return (%30)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@torch.jit.script\n",
    "def compute(x, y):\n",
    "  if bool(x[0] == 42):\n",
    "      z = 5\n",
    "  else:\n",
    "      z = 10\n",
    "  x = torch.ops.my_ops.warp_perspective(x, torch.eye(3))\n",
    "  return x.matmul(y) + z\n",
    "\n",
    "print(compute.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%x.1 : Tensor,\n",
      "      %y.1 : Tensor):\n",
      "  %31 : int = prim::Constant[value=1]()\n",
      "  %21 : NoneType = prim::Constant()\n",
      "  %3 : int = prim::Constant[value=0]() # /tmp/ipykernel_26022/3716228572.py:5:12\n",
      "  %8 : int = prim::Constant[value=42]() # /tmp/ipykernel_26022/3716228572.py:5:21\n",
      "  %13 : int = prim::Constant[value=5]() # /tmp/ipykernel_26022/3716228572.py:6:10\n",
      "  %14 : int = prim::Constant[value=10]() # /tmp/ipykernel_26022/3716228572.py:8:10\n",
      "  %20 : int = prim::Constant[value=3]() # /tmp/ipykernel_26022/3716228572.py:9:53\n",
      "  %5 : Tensor = aten::select(%x.1, %3, %3) # /tmp/ipykernel_26022/3716228572.py:5:10\n",
      "  %7 : Tensor = aten::select(%5, %3, %3) # /tmp/ipykernel_26022/3716228572.py:5:10\n",
      "  %9 : Tensor = aten::eq(%7, %8) # /tmp/ipykernel_26022/3716228572.py:5:10\n",
      "  %11 : bool = aten::Bool(%9) # /tmp/ipykernel_26022/3716228572.py:5:5\n",
      "  %z : int = prim::If(%11) # /tmp/ipykernel_26022/3716228572.py:5:2\n",
      "    block0():\n",
      "      -> (%13)\n",
      "    block1():\n",
      "      -> (%14)\n",
      "  %25 : Tensor = aten::eye(%20, %21, %21, %21, %21) # /tmp/ipykernel_26022/3716228572.py:9:43\n",
      "  %x.7 : Tensor = my_ops::warp_perspective(%x.1, %25) # /tmp/ipykernel_26022/3716228572.py:9:6\n",
      "  %29 : Tensor = aten::matmul(%x.7, %y.1) # /tmp/ipykernel_26022/3716228572.py:10:9\n",
      "  %32 : Tensor = aten::add(%29, %z, %31) # /tmp/ipykernel_26022/3716228572.py:10:9\n",
      "  return (%32)\n",
      "\n",
      "tensor(236.2102)\n"
     ]
    }
   ],
   "source": [
    "torch.ops.load_library(\"warp_perspective/build/libwarp_perspective.so\")\n",
    "\n",
    "@torch.jit.script\n",
    "def compute(x, y):\n",
    "  if bool(x[0][0] == 42):\n",
    "      z = 5\n",
    "  else:\n",
    "      z = 10\n",
    "  x = torch.ops.my_ops.warp_perspective(x, torch.eye(3))\n",
    "  return x.matmul(y) + z\n",
    "\n",
    "print(compute.graph)\n",
    "print(compute(torch.randn(32, 32), torch.rand(8, 3)).sum())\n",
    "\n",
    "compute.save(\"build/example.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "8a6b5a67c5d774b05f6659b16625b575f0390caee0a071a25b205e3940b26b24"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
